{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 Evaluating Classifiers\n",
    "\n",
    "> COM6018\n",
    "\n",
    "*Copyright &copy; 2024 Jon Barker, University of Sheffield. All rights reserved*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook have been written to accompany the Face Verification assignment. The notebook is unlike the previous labs notebooks, in that it is not a step-by-step guide to a solution. Instead, it contains some notes and snippets of code that you may find useful. The lab uses ideas from the lecture on classifier evaluation and applies them to the assignment data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment makes use of a number of data files that you will need to download from the following location:\n",
    "\n",
    "https://drive.google.com/drive/folders/10y3e2zKkh0lVpRZ3WC21Uu-v-EcbBSYs?usp=sharing\n",
    "\n",
    "As described in the assignment handout, you are provided with the following files:\n",
    "\n",
    "- `train.joblib` - the full training dataset\n",
    "- `eval1.joblib` - a dataset for evaluating your model\n",
    "- `baseline_model.joblib` - pre-trained kNN models, i.e., a baseline solution\n",
    "\n",
    "If you have not downloaded these already, do so now and store them in the same directory as this notebook.\n",
    "\n",
    "We will then load the datasets and the baseline model.\n",
    "\n",
    "### 2.1 The training data\n",
    "\n",
    "We will first load the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "data_train = joblib.load('train.joblib')\n",
    "print(data_train.keys())\n",
    "print(data_train['data'].shape)\n",
    "print(data_train['target'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a 2-D array of 2200 rows of 5828 values, where each row represents the pixels in a pair of images of shape 62 rows by 47 colums. For convenience we will reshape this into a 4-D array off 2200 x 2 x 62 x 47, i.e., 2200 samples of 2 images of 62 by 47 pixels. We will then store the reshaped data back in the data_train dictionary under a key called 'images'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train['images'] = data_train['data'].reshape((2200, 2, 62, 47))\n",
    "print(data_train['images'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write a function to take any image pair and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image_pair(images, n):\n",
    "    \"\"\"Display the nth image pair\"\"\"\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(images[n, 0], cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(images[n, 1], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "# show the 100th image pair\n",
    "display_image_pair(data_train['images'], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loading the evaluation data\n",
    "\n",
    "We will now load the data and reshape it in the same way that we reshape the training data.  Note that for the evaluation data there are 1000 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = joblib.load('eval1.joblib')\n",
    "data_eval['images'] = data_eval['data'].reshape((1000, 2, 62, 47))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that this has worked we will use our previous display function to show the 100th image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_pair(data_eval['images'], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try calling the display function with different values for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE SOLUTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your jupyter environment allows the use of widgets then the following code should allow you to browse through the training data image set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to pip install the ipywidget package (-q supresses the pip output)\n",
    "!pip -q install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "\n",
    "index_slider = IntSlider(value=0, min=0, max=2199, description=\"Image Pair Index\")\n",
    "\n",
    "\n",
    "def display_image_pair_wrapper(n):\n",
    "    \"\"\"Provides a 1-parameter interface for display_image_pair\"\"\"\n",
    "    display_image_pair(data_train['images'], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(display_image_pair_wrapper, n=index_slider);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 The baseline model\n",
    "\n",
    "A baseline model has been trained for you and stored in the files `baseline_model.joblib`. This can be loaded using the `joblib` library. The code below loads model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('baseline_model.joblib')\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that the print statement provides a description of the model. You can see that it is Pipeline with a single step, the KNN Classifier, constructed with $k=1$. The performance of this model is not great and it should be easy for you to improve on it.\n",
    "\n",
    "We can check the performance by using the model's score method and passing the evaluation data as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_correct = model.score(data_eval['data'], data_eval['target']) * 100 \n",
    "print(f'The classifier is {percent_correct:.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a score of 56.3%. This is significantly above chance (50%) but there is plenty of room for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Retraining your own KNN model\n",
    "\n",
    "We should be able to replicate the baseline model score by training our own KNN.\n",
    "\n",
    "### 3.1 Training a KNN\n",
    "\n",
    "Below we make a classifier, train it and then evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a KNN classifier with k=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Repeating using a pipeline\n",
    "\n",
    "We will now repeat the process using a pipeline. The pipeline will have just the classifier and no preprocessing steps. This is not very useful but it illustrates the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with the KNN classifier\n",
    "knn_pipeline = Pipeline([\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=1))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "knn_pipeline.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = knn_pipeline.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should get the same result.\n",
    "\n",
    "But we can now add some preprocessing steps to the pipeline with very little modification to the code. For example, if we want to do standard scaler normalisation of the pixel features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a pipeline with the KNN classifier\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Normalize the data\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=1))  # Step 2: Perform the classification\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "knn_pipeline.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = knn_pipeline.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Writing your own pipeline processing steps\n",
    "\n",
    "What happens if you want to add your own data processing step to the pipe, i.e., a function that is not already defined in sklearn. \n",
    "\n",
    "For example, let us imaging that we write a function that downsamples the images by taking every nth pixel. We will write a function that takes the data as input, processes it and then returns the processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, factor):\n",
    "    \"\"\" A crude downsampling of the images\"\"\"\n",
    "    return data[:, ::factor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is fine but to put it compatible with the sklearn pipeline framework, we need to make it part of a 'custom transformer' class. A transformer is a class that provides a 'transform' method that applies the transform. It can also have some parameters (which might be learnable), and a 'fit' method that is used to learn the parameters. \n",
    "\n",
    "The class has to inherit from a pair of sklearn classes: BaseEstimator and TransformerMixin. The code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MyDownsample(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=2):\n",
    "        self.factor = factor # The downsampling factor\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # There is no fitting\n",
    "    \n",
    "    def transform(self, data, y=None):\n",
    "        \"\"\"Downsample the data\"\"\"\n",
    "        return data[:,::self.factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this in our pipeline as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with the KNN classifier\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Normalize the data\n",
    "    ('downsample', MyDownsample(factor=2)), # Step 2: Downsample by a factor of 2\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=1))  # Step 3: Perform the classification\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "knn_pipeline.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = knn_pipeline.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save this pipeline to a model file in the usual way. If someone want to load and use your model file then they will be able to do so as long as:\n",
    "\n",
    "- Dependencies Are Installed: The person receiving the model must have the same Python environment with compatible versions of scikit-learn and any other libraries (e.g., numpy, joblib).\n",
    "\n",
    "- Custom Transformers Are Available: If your pipeline includes a custom transformer like MyDownsample, they need access to its code to deserialize and use the model. This is because joblib serializes the references to the class, not the class definition itself.\n",
    "\n",
    "This will be fine for the assignment because you have been asked to provide your `train.py` code. But you need to ensure that any custom transformer classes that you have written are included in the `train.py` file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases like the above, where the transformer has no parameters that need to be fitted, you can simplify the code by using sklearn's 'FunctionTransformer' class, that will turn a simple function into a pipeline transformer for you. \n",
    "\n",
    "In this case you do not need to define a new class but can just define the function and use FunctionTransformer like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Below is the function that will be used in the pipeline...\n",
    "def my_downsample(data, factor):\n",
    "    return data[:, ::factor]\n",
    "\n",
    "# ... and here is how it is added to the pipeline. Note how FunctionTransformer wraps around my_downsample\n",
    "knn_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Normalize the data\n",
    "    ('downsample', FunctionTransformer(my_downsample, kw_args={'factor': 2})), # Step 2: Downsample\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=1))  # Step 3: Perform the classification\n",
    "])\n",
    "\n",
    "# Train the pipeline in the usual way\n",
    "knn_pipeline.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = knn_pipeline.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, trained pipelines using functions wrapped with FunctionTransformer like this can be save to joblib files and shared with others, as long as you also provide your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating using an ROC curve\n",
    "\n",
    "In the following, I have provided an example of how to generate an ROC curve.\n",
    "\n",
    "First, KNNs are not naturally probabilistic classifiers and so do not provide a very meaningful probability value when calling 'score_proba'. A value can be obtained when a large value of K is used but a large value of K gives poorer performance. So to make a better illustration I am swapping to using a LogisticRegression classifier.\n",
    "\n",
    "The code below follows almost exactly the code in this weeks tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ... and here is how it is added to the pipeline. Note how FunctionTransformer wraps around my_downsample\n",
    "lr_pipeline = Pipeline([\n",
    "    ('downsample', FunctionTransformer(my_downsample, kw_args={'factor': 2})), # Step 2: Downsample\n",
    "    ('classifier', LogisticRegression(C=0.01, solver='liblinear'))  # Step 3: Perform the classification\n",
    "])\n",
    "\n",
    "# Train the pipeline in the usual way\n",
    "lr_pipeline.fit(data_train['data'], data_train['target'])\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = lr_pipeline.score(data_eval['data'], data_eval['target']) * 100\n",
    "print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now, i) use predict_proba to get scores; ii) calculate the FPR and TPR for different score thresholds and iii) compute the area under the curve (AUC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_scores = lr_pipeline.predict_proba(data_eval['data'])\n",
    "eval_scores_positive_class = eval_scores[:,1]\n",
    "fpr, tpr, _ = roc_curve(data_eval['target'], eval_scores_positive_class)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below then plots the ROC curve in a similar style to in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', lw=2, label='Random Guess')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we acan see that the AUC is very close to 0.5. The ROC curve lies very close to that which would be obtained if we were simply guessing. This is not surprising given that the accuracy (52.2%) was also close to chance performance. \n",
    "\n",
    "You may ask whether 52.2% is significantly better than chance in formal statistical sense. We can compute a z-score and a p-value using a Binomial test. The"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Parameters\n",
    "n = 1000  # Total trials\n",
    "k = 522   # Correct guesses\n",
    "p_null = 0.5  # Null hypothesis: chance level\n",
    "\n",
    "# Observed proportion\n",
    "p_observed = k / n\n",
    "\n",
    "# Binomial test\n",
    "binom_result = stats.binomtest(k, n, p_null, alternative='greater')\n",
    "p_value_binomial = binom_result.pvalue\n",
    "print(f\"Binomial test p-value: {p_value_binomial:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is above than the standard 0.05\\% threshold conventionally used for statistical significance. i.e. if we were simply guessing, we would get a result as least as good as this 8.69% of the time. We would not be allowed to call this result significant. Note that this does not mean that our classifier is not doing better than guessing, just that we have not got any evidence that it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Runnning Python script from the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an exercise, extract the code from this notebook into a .py file.  You can use the template below to help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Python script for evaluating a model\"\"\"\n",
    "import joblib\n",
    "# Add all the import statements that you need.\n",
    "\n",
    "# Add all the function definitions that you need\n",
    "\n",
    "def main():\n",
    "    \"\"\"Function to evaluate a model.\"\"\"\n",
    "\n",
    "    # This is the first function that gets called. Start adding code here.\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2024 Jon Barker, University of Sheffield. All rights reserved*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
